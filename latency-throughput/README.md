# âš™ï¸ Latency and Throughput

## ðŸš€ Latency

**Latency** refers to the **delay or lag** between sending a request and receiving a response.  
It measures **how long it takes** for data to travel from the **client â†’ server â†’ client** again.

ðŸ§® **Measured in:** milliseconds (ms) or seconds (s)

In short:  
> **Latency = Network Delay + Computational Delay**

---

### ðŸ§  Example

When a client sends a request to a server:
1. The request travels through the **network** to reach the server.  
2. The server processes it, possibly querying a **database** or another service.  
3. The response travels back through the **network** to the client.

Each step adds some delay (latency).

Letâ€™s assume:
- **tâ‚** â†’ network delay (client â†’ server)  
- **tâ‚‚** â†’ computational delay (server processing time)  
- **tâ‚ƒ** â†’ network delay (server â†’ client)

Then:

> **Total Latency = tâ‚ + tâ‚‚ + tâ‚ƒ**

---

## âš¡ Throughput

**Throughput** represents **how much data or load** a system can handle **over a given period of time**.

ðŸ§® **Measured in:** bits per second (bps), often **Megabits per second (Mbps)**

It tells us how *efficiently* a system processes requests or transmits data.

> **Example:**  
> A database can write **100 records per second** into a table.  
> If more data arrives than it can handle, it may show **timeout or overload errors**.

---

## ðŸ” Relationship Between Latency and Throughput

While **latency** and **throughput** are different, they are closely connected:

| Concept | Meaning | Effect |
|----------|----------|--------|
| **Latency** | Time delay in a single request/response | Higher latency â†’ Slower responses |
| **Throughput** | Amount of work done per unit time | Higher latency â†’ Lower throughput |

ðŸ’¡ In simple terms:  
- If **latency is high**, each request takes longer â†’ **throughput decreases**  
- If **latency is low**, more requests can be handled in the same time â†’ **throughput increases**

---

## ðŸŒ Networking Context

In networking, **throughput** depends on:
- Network bandwidth  
- Packet loss  
- Network congestion  
- Distance between client and server  

And **latency** depends on:
- Physical distance  
- Network routing hops  
- Server load and processing time  

---

### ðŸ Summary

| Term | Definition | Unit | Example |
|------|-------------|------|----------|
| **Latency** | Time delay between request and response | ms or s | Request takes 150ms to complete |
| **Throughput** | Amount of data processed per second | Mbps | API handles 200 requests/sec |

---

### ðŸ’¬ In Short
> **Latency** â†’ How fast a single request completes.  
> **Throughput** â†’ How many requests the system can handle per second.
